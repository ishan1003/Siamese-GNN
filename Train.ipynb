{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2f5f59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, Data\n",
    "\n",
    "class SingleFileEmbeddingPairDataset(Dataset):\n",
    "    def __init__(self, json_path):\n",
    "        super().__init__(os.path.dirname(json_path))\n",
    "        # Load the JSON (which is a dict of model numbers)\n",
    "        with open(json_path, 'r') as f:\n",
    "            model_dict = json.load(f)\n",
    "            # Flatten all model pairs into a list:\n",
    "            self.all_pairs = []\n",
    "            for model_num, pair in model_dict.items():\n",
    "                # Optionally store model_num if you want it later: pair['model_num'] = model_num\n",
    "                self.all_pairs.append(pair)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.all_pairs[idx]\n",
    "\n",
    "        # Extract embeddings for A and B\n",
    "        A_ids = sorted(pair['A_embeddings'].keys(), key=lambda x: int(x))\n",
    "        xA = torch.tensor([pair['A_embeddings'][xtid] for xtid in A_ids], dtype=torch.float)\n",
    "        B_ids = sorted(pair['B_embeddings'].keys(), key=lambda x: int(x))\n",
    "        xB = torch.tensor([pair['B_embeddings'][xtid] for xtid in B_ids], dtype=torch.float)\n",
    "\n",
    "        # Dummy edge indices (empty for now)\n",
    "        edge_indexA = torch.empty((2,0), dtype=torch.long)\n",
    "        edge_indexB = torch.empty((2,0), dtype=torch.long)\n",
    "\n",
    "        A_id_to_idx = {int(aid): idx for idx, aid in enumerate(A_ids)}\n",
    "        B_id_to_idx = {int(bid): idx for idx, bid in enumerate(B_ids)}\n",
    "\n",
    "        mappings = []\n",
    "        for a, b in pair['mappings']:\n",
    "            idx_a = -1 if a == 'NULL' else A_id_to_idx[int(a)]  \n",
    "            idx_b = -1 if b == 'NULL' else B_id_to_idx[int(b)]\n",
    "            mappings.append([idx_a, idx_b])\n",
    "\n",
    "        matches = torch.tensor(mappings, dtype=torch.long)\n",
    "\n",
    "        dataA = Data(x=xA, edge_index=edge_indexA, xt_entity_ids=A_ids)\n",
    "        dataB = Data(x=xB, edge_index=edge_indexB, xt_entity_ids=B_ids)\n",
    "        return dataA, dataB, matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bf45e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class GraphEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, out_dim, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.conv2 = SAGEConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = SAGEConv(hidden_dim, out_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.bn1(self.conv1(x, edge_index)))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.relu(self.bn2(self.conv2(x, edge_index)))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SiameseGNN(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, proj_dim=None, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.encoder = GraphEncoder(in_dim, hidden_dim, out_dim, dropout)\n",
    "        \n",
    "        # Optional projection MLP for better embedding alignment\n",
    "        if proj_dim is not None:\n",
    "            self.projector = nn.Sequential(\n",
    "                nn.Linear(out_dim, proj_dim),\n",
    "                nn.BatchNorm1d(proj_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(proj_dim, proj_dim)\n",
    "            )\n",
    "            self.final_dim = proj_dim\n",
    "        else:\n",
    "            self.projector = None\n",
    "            self.final_dim = out_dim\n",
    "\n",
    "    def forward(self, data1, data2):\n",
    "        h1 = self.encoder(data1.x, data1.edge_index)\n",
    "        h2 = self.encoder(data2.x, data2.edge_index)\n",
    "\n",
    "        if self.projector is not None:\n",
    "            h1 = self.projector(h1)\n",
    "            h2 = self.projector(h2)\n",
    "\n",
    "        # Normalize embeddings for contrastive or cosine losses\n",
    "        # h1 = F.normalize(h1, p=2, dim=-1)\n",
    "        # h2 = F.normalize(h2, p=2, dim=-1)\n",
    "        return h1, h2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "face5ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- Core Contrastive Margin Loss ---\n",
    "def contrastive_margin_loss(emb1, emb2, matches_pos, matches_neg, margin=1.0):\n",
    "    \"\"\"\n",
    "    emb1: [N1, D]\n",
    "    emb2: [N2, D]\n",
    "    matches_pos: [K1, 2]  -> positive pairs (valid correspondences)\n",
    "    matches_neg: [K2, 2]  -> negative pairs (non-correspondences)\n",
    "    margin: margin distance for negatives\n",
    "    \"\"\"\n",
    "    if matches_pos.numel() == 0:\n",
    "        # No positives in this batch → zero loss but keep graph\n",
    "        return (emb1.sum() * 0.0) + (emb2.sum() * 0.0)\n",
    "\n",
    "    # ---- Positive loss (want small distances) ----\n",
    "    pos1 = emb1[matches_pos[:, 0]]\n",
    "    pos2 = emb2[matches_pos[:, 1]]\n",
    "    pos_dist = (pos1 - pos2).pow(2).sum(dim=1)\n",
    "    pos_loss = pos_dist.mean()\n",
    "\n",
    "    # ---- Negative loss (want large distances > margin) ----\n",
    "    if matches_neg.numel() == 0:\n",
    "        neg_loss = torch.tensor(0.0, device=emb1.device)\n",
    "    else:\n",
    "        neg1 = emb1[matches_neg[:, 0]]\n",
    "        neg2 = emb2[matches_neg[:, 1]]\n",
    "        neg_dist = (neg1 - neg2).pow(2).sum(dim=1)\n",
    "        neg_loss = F.relu(margin - neg_dist).mean()\n",
    "\n",
    "    return pos_loss + neg_loss\n",
    "\n",
    "\n",
    "# --- Random negative sampling ---\n",
    "def get_random_negatives(matches_pos, emb1_size, emb2_size, num_neg=None):\n",
    "    num_pos = matches_pos.size(0)\n",
    "    num_neg = num_neg or num_pos\n",
    "\n",
    "    rand_A = torch.randint(0, emb1_size, (num_neg,))\n",
    "    rand_B = torch.randint(0, emb2_size, (num_neg,))\n",
    "    mask = torch.ones(num_neg, dtype=torch.bool)\n",
    "    pos_set = set(map(tuple, matches_pos.tolist()))\n",
    "    for i in range(num_neg):\n",
    "        if (rand_A[i].item(), rand_B[i].item()) in pos_set:\n",
    "            mask[i] = False\n",
    "    return torch.stack([rand_A[mask], rand_B[mask]], dim=1)\n",
    "\n",
    "\n",
    "# --- Hard negative sampling ---\n",
    "def get_hard_negatives(emb1, emb2, matches_pos, top_k=3):\n",
    "    \"\"\"\n",
    "    Select hardest negatives (closest embeddings not in positive set)\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        dist = torch.cdist(emb1, emb2, p=2)  # [N1, N2]\n",
    "        pos_mask = torch.zeros_like(dist, dtype=torch.bool)\n",
    "        pos_mask[matches_pos[:, 0], matches_pos[:, 1]] = True\n",
    "        dist[pos_mask] = 1e6  # mask out positives\n",
    "\n",
    "        # Select top-k smallest distances as negatives\n",
    "        neg_indices = dist.topk(k=top_k, largest=False).indices  # [N1, top_k]\n",
    "        matches_neg = []\n",
    "        for i in range(neg_indices.size(0)):\n",
    "            for j in neg_indices[i]:\n",
    "                matches_neg.append([i, j.item()])\n",
    "        matches_neg = torch.tensor(matches_neg, dtype=torch.long, device=emb1.device)\n",
    "    return matches_neg\n",
    "\n",
    "\n",
    "# --- Mixed negative sampling (recommended) ---\n",
    "def get_mixed_negatives(emb1, emb2, matches_pos, ratio=0.5, top_k=3):\n",
    "    \"\"\"\n",
    "    Combines random + hard negatives\n",
    "    \"\"\"\n",
    "    hard_negs = get_hard_negatives(emb1, emb2, matches_pos, top_k)\n",
    "    rand_negs = get_random_negatives(matches_pos, emb1.size(0), emb2.size(0))\n",
    "    num_hard = int(ratio * min(len(hard_negs), len(rand_negs)))\n",
    "    if num_hard == 0:\n",
    "        return rand_negs\n",
    "    mixed = torch.cat([hard_negs[:num_hard], rand_negs[:num_hard]], dim=0)\n",
    "    return mixed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "050a8208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(emb1, emb2, matches):\n",
    "    # emb1: [N1, D], emb2: [N2, D], matches: [K,2]\n",
    "    valid = matches[:,1] != -1\n",
    "    indices1 = matches[valid, 0]\n",
    "    indices2 = matches[valid, 1]\n",
    "\n",
    "    if len(indices1) == 0:\n",
    "        return None  # avoid NaN\n",
    "\n",
    "    dists = torch.cdist(emb1, emb2)  # [N1, N2]\n",
    "    # For each ground-truth emb1 index, which emb2 is closest\n",
    "    min_indices = torch.argmin(dists[indices1], dim=1)\n",
    "    correct = (min_indices == indices2).float()\n",
    "    return correct.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ab13fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_topk_accuracy(emb1, emb2, matches, k=5):\n",
    "    valid = matches[:,1] != -1\n",
    "    indices1 = matches[valid, 0]\n",
    "    indices2 = matches[valid, 1]\n",
    "\n",
    "    if len(indices1) == 0:\n",
    "        return None\n",
    "\n",
    "    dists = torch.cdist(emb1, emb2)\n",
    "\n",
    "    actual_k = min(k, emb2.shape[0])\n",
    "    if actual_k == 0:\n",
    "        return None  # no candidates\n",
    "\n",
    "    topk = torch.topk(-dists[indices1], actual_k, dim=1).indices\n",
    "    correct = torch.any(topk == indices2.unsqueeze(1), dim=1).float()\n",
    "    return correct.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabec65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  Load dataset\n",
    "dataset = SingleFileEmbeddingPairDataset(\n",
    "    \"C:\\\\Users\\\\Z0054udc\\\\Downloads\\\\Siamese GNN\\\\XT_merged_doubled.json\"\n",
    ")\n",
    "print(f\"Found {len(dataset)} dataset entries.\")\n",
    "if len(dataset) == 0:\n",
    "    raise ValueError(\"ERROR: No JSON files found!\")\n",
    "\n",
    "#  Device setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "#  Model and optimizer\n",
    "model = SiameseGNN(in_dim=15, hidden_dim=64, out_dim=32).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "#  Training hyperparameters\n",
    "epochs = 150\n",
    "grad_accum_steps = 8        # Simulates batch size = 8\n",
    "loss_history, top1_history, top5_history = [], [], []\n",
    "\n",
    "#  Training loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_top1 = 0.0\n",
    "    total_top5 = 0.0\n",
    "    num_acc = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i in tqdm(range(len(dataset)), desc=f\"Epoch {epoch+1}\"):\n",
    "        data1, data2, matches = dataset[i]\n",
    "        data1, data2, matches = data1.to(device), data2.to(device), matches.to(device)\n",
    "\n",
    "        # Forward pass for this pair\n",
    "        emb1, emb2 = model(data1, data2)\n",
    "        matches_pos = matches[(matches[:, 0] != -1) & (matches[:, 1] != -1)]\n",
    "        matches_neg = get_mixed_negatives(emb1, emb2, matches_pos, ratio=0.5, top_k=3)\n",
    "        loss = contrastive_margin_loss(emb1, emb2, matches_pos, matches_neg)\n",
    "        loss.backward()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # --- Accuracy tracking\n",
    "        acc1 = batch_accuracy(emb1, emb2, matches)\n",
    "        acc5 = batch_topk_accuracy(emb1, emb2, matches, k=5)\n",
    "        if acc1 is not None and acc5 is not None:\n",
    "            total_top1 += acc1\n",
    "            total_top5 += acc5\n",
    "            num_acc += 1\n",
    "\n",
    "        # --- Gradient accumulation ---\n",
    "        if (i + 1) % grad_accum_steps == 0 or (i + 1) == len(dataset):\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "    # ---- Epoch summary ----\n",
    "    avg_loss = total_loss / len(dataset)\n",
    "    avg_top1 = (total_top1 / num_acc) * 100 if num_acc > 0 else 0.0\n",
    "    avg_top5 = (total_top5 / num_acc) * 100 if num_acc > 0 else 0.0\n",
    "\n",
    "    loss_history.append(avg_loss)\n",
    "    top1_history.append(avg_top1)\n",
    "    top5_history.append(avg_top5)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:03d}: Loss = {avg_loss:.4f}, Top-1 = {avg_top1:.2f}%, Top-5 = {avg_top5:.2f}%\")\n",
    "\n",
    "# ✅ Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_history, label=\"Loss\", color='firebrick')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Contrastive Loss Curve\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ✅ Plot accuracy curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(top1_history, label=\"Top-1 Accuracy (%)\", color='royalblue')\n",
    "plt.plot(top5_history, label=\"Top-5 Accuracy (%)\", linestyle=\"--\", color='seagreen')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Accuracy Over Training\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "db7e726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"siamese_gnn.pth\")\n",
    "# To load: model.load_state_dict(torch.load(\"siamese_gnn.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
